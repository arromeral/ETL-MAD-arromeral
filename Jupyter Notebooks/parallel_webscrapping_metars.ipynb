{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb871b5c",
   "metadata": {},
   "source": [
    "# EXTRACCIÓN DE PARTES METAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bebdf",
   "metadata": {},
   "source": [
    "## En este Notebook se va a desarrollar el proceso de estracción de todos los partes METAR del Aeropuerto Adolfo Suárez Madrid-Barajas en el periodo comprendido entre el 01-11-2022 y el 31-10-2023, es decir, 1 año completo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfd193",
   "metadata": {},
   "source": [
    "Un parte o código METAR es el estándar internacional en aviación del formato del código utilizado para emitir periódicamente informes de las observaciones meteorológicas en los aeródromos y aeropuertos.\n",
    "\n",
    "Se trata de un reporte breve en forma de código alfanumérico que aporta información meteorológica detallada de un momento determinado en un aeropuerto concreto. Básicamente, es una sucesión de letras y números que se emiten periódicamente por los aeropuertos y aeródromos. \n",
    "\n",
    "Estos partes se emiten periódicamente, generalmente cada 30 minutos, salvo circunstancias excepcionales en las que se pueden emitir partes adicionales. \n",
    "\n",
    "Aunque pueden ser dificíl de descifrar para el usuario general, contienen información de gran relevancia para la actividad aérea relativa a la temperatura, precipitaciones, visibilidad en pista, viento y ráfagas entre otro. Por suerte, se pueden encontrar webs que traducen esta información a un lenguaje más amable y que además mantienen registros de los partes en el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fffe93",
   "metadata": {},
   "source": [
    "## Para ello se va a utilizar la técnica de extracción de datos \"webscrapping\" sobre la web [tutiempo](https://www.tutiempo.net/registros/lemd) que mantiene registros de estos partes desde hace vários años.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff1426",
   "metadata": {},
   "source": [
    "### Las librerías que se van a emplear principalmente para el proceso son:\n",
    "- **selenium** \n",
    "- **joblib**\n",
    "- **pandas** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462b2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\daarr\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dba2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select   # seleccion de un dropdown\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from joblib._parallel_backends import LokyBackend\n",
    "import asyncio\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cebbd7",
   "metadata": {},
   "source": [
    "## Se habilitan algunas opciones de interés para el driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a68897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver configuration\n",
    "opciones=Options()\n",
    "\n",
    "opciones.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "opciones.add_experimental_option('useAutomationExtension', False)\n",
    "opciones.headless=False    # si True, no aperece la ventana (headless=no visible)\n",
    "opciones.add_argument('--start-maximized')         # comienza maximizado\n",
    "opciones.add_argument('--incognito')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddff1992",
   "metadata": {},
   "source": [
    "# Despues de hacer un estudio sobre la estructura de la web para plantear el proceso de extracción, se observa que en cada página se encuentran exclusivamente los partes de un día en concreto( de media unos 48).\n",
    "\n",
    "## Además, se comprueba que al pasar de un día a otro el *link* de la web varía siguiendo un patrón claro como el siguiente:\n",
    "\n",
    "### - ...tutiempo.net/records/lemd/{<span style=\"color:red\">dia</span>}-{<span style=\"color:red\">mes</span>}-{<span style=\"color:red\">año</span>}.html\n",
    "\n",
    "### Este formate de *links* es de especial ayuda, ya que nos va a permitir paralelizar el proceso con **joblib**, reduciendo considerablemente el tiempo de extracción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a8550",
   "metadata": {},
   "source": [
    "## Vamos, por tanto, a generar los diferentes *links* necesarios, en este caso únicamente los del año 2023, de Enero a Octubre.\n",
    "\n",
    "## De momento no nos vamos a preocupar de los días de cada mes, generando 31 links para cada uno de los meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "462ca77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses = [\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\"]\n",
    "dias = []\n",
    "for i in range(1,32):\n",
    "    dias.append(str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7229f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for mes in meses:\n",
    "    for dia in dias:\n",
    "        urls.append(f'https://en.tutiempo.net/records/lemd/{dia}-{mes}-2023.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "efb915c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.tutiempo.net/records/lemd/1-october-2023.html'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[279]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e876fd5",
   "metadata": {},
   "source": [
    "# La siguiente función <span style=\"color:red\">extraer</span>, engloba el proceso de extraccíon de los datos necesarios para cada una de las *urls*.\n",
    "\n",
    "## Los comentaríos de la función explican paso por paso la lógica del proceso.\n",
    "## A modo de resumen, el driver entra en la página, *clicka* aceptar en los popups de cookies, extrae los datos necesarios almacenadolos en una tabla y finálmente devuelve un DataFrame con los registro METAR de ese día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b81576c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer(url):\n",
    "    table = []  # Inicializa table como una lista vacía\n",
    "    columns = [] # Inicializa columns como una lista vacía\n",
    "    \n",
    "    try:\n",
    "        # inicia el driver en la url indicada\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(2) #espera a cargar la página\n",
    "        # acepta normas\n",
    "        aceptar = driver.find_element(By.XPATH,'/html/body/div[18]/div[2]/div[1]/div[2]/div[2]/button[1]')\n",
    "        aceptar.click()\n",
    "\n",
    "        time.sleep(2) #espera a cargar la página\n",
    "        #acepta cookies\n",
    "        aceptar = driver.find_element(By.XPATH, '//*[@id=\"DivAceptarCookies\"]/div/a[2]')\n",
    "        aceptar.click()\n",
    "        \n",
    "        time.sleep(2) #espera a cargar la página\n",
    "        day = driver.find_elements(By.XPATH, '//table//tbody//tr')[1].text #almacena el día\n",
    "        table = [row.text.split('\\n')[0:3] + row.text.replace(' km/h', '').split('\\n')[-1].split(' ', 2)\n",
    "                 for row in driver.find_elements(By.XPATH, '//table//tbody//tr')[3::2]]  #copia los registros\n",
    "\n",
    "        columns = [\"Day\", \"Hour\", \"Condition\", \"Temperature\", \"Wind\", \"Relative_hum\", \"Pressure\"] #añade las columnas\n",
    "\n",
    "        for i in table:\n",
    "            i.insert(0, day) #inserta los registros en la tabla\n",
    "            \n",
    "        return pd.DataFrame(table, columns=columns) #devuelve un dataframe con los datos de ese día \n",
    "        \n",
    "    except Exception as e:  # Captura cualquier excepción y muestra el mensaje de error\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"Error en la URL: {url}\")\n",
    "        # En caso de error, simplemente se devolverá la lista vacía 'table'\n",
    "        return pd.DataFrame(table, columns=columns) \n",
    "    driver.quit()\n",
    "#     return pd.DataFrame(table, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac6a28",
   "metadata": {},
   "source": [
    "## El siguiente código inicia el proceso de extracción usando la paralelización con 8 núcleos, es decir, realiza el proceso en *8 urls* simultáneamente.\n",
    "\n",
    "Aunque se podría haber utilizado el proceso una única vez, se decide hacer una extracción por cada uno de los meses, mediante los índices de la tabla de urls, con el objetivo de tener un mayor control ante posibles incidencias del proceso, y poder obtener diferentes registros mensuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af3976da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb9b8755c2842249cbafc57336b5291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  31 out of  31 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paralelo = Parallel(n_jobs=8, verbose=True)\n",
    "\n",
    "lst_df = paralelo(delayed(extraer)(url) for url in tqdm(urls[279:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d863f",
   "metadata": {},
   "source": [
    "## Obtenidos los DataFrame para cada unos de los días del mes, se contatenan los DataFrame y se hace una breve exploración sobre el resultado para observar si se han obtenido todos los registros necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f57a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "metar_october_2023 = pd.concat(lst_df)\n",
    "print(len(metar_october_2023))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b887ef",
   "metadata": {},
   "source": [
    "## Finalmente se exportan a un archivo *.csv* cada uno de los DataFrames mensuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf525e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metar_october_2023.to_csv(\"../data/metar/metar_october_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd52f38",
   "metadata": {},
   "source": [
    "# A partir de aquí se repite el proceso para los meses de Noviembre y Diciembre de 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "65fa6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "meses2 = [\"november\",\"december\"]\n",
    "dias2 = []\n",
    "for i in range(1,32):\n",
    "    dias2.append(str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8b3bc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls22 = []\n",
    "for mes in meses2:\n",
    "    for dia in dias2:\n",
    "        urls22.append(f'https://en.tutiempo.net/records/lemd/{dia}-{mes}-2022.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d99428e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.tutiempo.net/records/lemd/1-december-2022.html'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls22[31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "75473eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811b388fcd52436d9ccca5d299c3a261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  31 out of  31 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paralelo = Parallel(n_jobs=8, verbose=True)\n",
    "\n",
    "lst_df = paralelo(delayed(extraer)(url) for url in tqdm(urls22[31:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ef8f40f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "metar_december_2022 = pd.concat(lst_df)\n",
    "# df[df.Condition == \"Sunday\"]\n",
    "print(len(metar_december_2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5bd96f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "metar_december_2022.to_csv(\"../data/metar/metar_december_2022.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
